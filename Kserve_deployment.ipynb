{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e287f0e7-cb4c-4748-ac4c-524604dfef09",
   "metadata": {},
   "source": [
    "# Deploy the Custom Predictor on KServe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e12831-932c-4c2f-ad6e-27a210f92e00",
   "metadata": {},
   "source": [
    "## Install KServe\n",
    "In case kfserving is installed, first we uninstall it and then install the KServe SDK using the following command. Restart the kernel after installing the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9190626-d07a-436d-81b1-5f52b170b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping kfserving as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall kfserving -y\n",
    "!pip install kserve==0.7 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc5682-0dc9-4202-b382-ba2e9b605a35",
   "metadata": {},
   "source": [
    "## Import kubernetes.client and kserve packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8852639b-6e62-4493-8d51-a753c65e2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kserve\n",
    "from kubernetes.client import V1Container, V1ResourceRequirements\n",
    "from kserve import V1beta1InferenceService, V1beta1InferenceServiceSpec, V1beta1PredictorSpec\n",
    "from kserve import constants\n",
    "from kubernetes import client \n",
    "from kserve import KServeClient\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d5e63-bb0f-46c9-aed5-b3391bd351b2",
   "metadata": {},
   "source": [
    "## Declare Namespace\n",
    "Specify the nammespace, the InferenceService will be deployed in this namespace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2935214-c851-4fa0-8020-1335f5603abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = 'kubeflow-user-example-com'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd62bc-70d8-415f-9b56-57ce04d6ee4e",
   "metadata": {},
   "source": [
    "## Define the InferenceService\n",
    "Define the InferenceService based on several key parameters. In the predictor parameter, a V1beta1PredictorSpec object with a container image is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9da00b5-6bd3-47f0-843d-e866a8178516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving.kserve.io/v1beta1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'api_version': 'serving.kserve.io/v1beta1',\n",
       " 'kind': 'InferenceService',\n",
       " 'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'},\n",
       "              'cluster_name': None,\n",
       "              'creation_timestamp': None,\n",
       "              'deletion_grace_period_seconds': None,\n",
       "              'deletion_timestamp': None,\n",
       "              'finalizers': None,\n",
       "              'generate_name': None,\n",
       "              'generation': None,\n",
       "              'labels': None,\n",
       "              'managed_fields': None,\n",
       "              'name': 'tg-gcn-kserve',\n",
       "              'namespace': 'kubeflow-user-example-com',\n",
       "              'owner_references': None,\n",
       "              'resource_version': None,\n",
       "              'self_link': None,\n",
       "              'uid': None},\n",
       " 'spec': {'explainer': None,\n",
       "          'predictor': {'active_deadline_seconds': None,\n",
       "                        'affinity': None,\n",
       "                        'automount_service_account_token': None,\n",
       "                        'batcher': None,\n",
       "                        'canary_traffic_percent': None,\n",
       "                        'container_concurrency': None,\n",
       "                        'containers': [{'args': None,\n",
       "                                        'command': None,\n",
       "                                        'env': None,\n",
       "                                        'env_from': None,\n",
       "                                        'image': 'nzarayeneh/kserve-base:latest',\n",
       "                                        'image_pull_policy': None,\n",
       "                                        'lifecycle': None,\n",
       "                                        'liveness_probe': None,\n",
       "                                        'name': 'kserve-base',\n",
       "                                        'ports': None,\n",
       "                                        'readiness_probe': None,\n",
       "                                        'resources': {'limits': {'cpu': '500m',\n",
       "                                                                 'memory': '500Mi'},\n",
       "                                                      'requests': {'cpu': '100m',\n",
       "                                                                   'memory': '200Mi'}},\n",
       "                                        'security_context': None,\n",
       "                                        'startup_probe': None,\n",
       "                                        'stdin': None,\n",
       "                                        'stdin_once': None,\n",
       "                                        'termination_message_path': None,\n",
       "                                        'termination_message_policy': None,\n",
       "                                        'tty': None,\n",
       "                                        'volume_devices': None,\n",
       "                                        'volume_mounts': None,\n",
       "                                        'working_dir': None}],\n",
       "                        'dns_config': None,\n",
       "                        'dns_policy': None,\n",
       "                        'enable_service_links': None,\n",
       "                        'ephemeral_containers': None,\n",
       "                        'host_aliases': None,\n",
       "                        'host_ipc': None,\n",
       "                        'host_network': None,\n",
       "                        'host_pid': None,\n",
       "                        'hostname': None,\n",
       "                        'image_pull_secrets': None,\n",
       "                        'init_containers': None,\n",
       "                        'lightgbm': None,\n",
       "                        'logger': None,\n",
       "                        'max_replicas': None,\n",
       "                        'min_replicas': None,\n",
       "                        'node_name': None,\n",
       "                        'node_selector': None,\n",
       "                        'onnx': None,\n",
       "                        'overhead': None,\n",
       "                        'paddle': None,\n",
       "                        'pmml': None,\n",
       "                        'preemption_policy': None,\n",
       "                        'priority': None,\n",
       "                        'priority_class_name': None,\n",
       "                        'pytorch': None,\n",
       "                        'readiness_gates': None,\n",
       "                        'restart_policy': None,\n",
       "                        'runtime_class_name': None,\n",
       "                        'scheduler_name': None,\n",
       "                        'security_context': None,\n",
       "                        'service_account': None,\n",
       "                        'service_account_name': None,\n",
       "                        'set_hostname_as_fqdn': None,\n",
       "                        'share_process_namespace': None,\n",
       "                        'sklearn': None,\n",
       "                        'subdomain': None,\n",
       "                        'tensorflow': None,\n",
       "                        'termination_grace_period_seconds': None,\n",
       "                        'timeout': None,\n",
       "                        'tolerations': None,\n",
       "                        'topology_spread_constraints': None,\n",
       "                        'triton': None,\n",
       "                        'volumes': None,\n",
       "                        'xgboost': None},\n",
       "          'transformer': None},\n",
       " 'status': None}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='tg-gcn-kserve'\n",
    "kserve_version='v1beta1'\n",
    "api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "print(api_version)\n",
    "isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                kind=constants.KSERVE_KIND,\n",
    "                                metadata=client.V1ObjectMeta(\n",
    "                                   name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                       predictor=V1beta1PredictorSpec(\n",
    "                                           containers=[V1Container(image = \"nzarayeneh/kserve-base:latest\", \n",
    "                                                                   name = \"kserve-base\",\n",
    "                                                                    resources=client.V1ResourceRequirements(\n",
    "                                                                    requests={\"cpu\": \"100m\", \"memory\": \"200Mi\"},\n",
    "                                                                    limits={\"cpu\": \"500m\", \"memory\": \"500Mi\"}\n",
    "        )\n",
    ")]\n",
    "                                       )\n",
    "                                   )\n",
    "                                )\n",
    "isvc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fad7df-ebba-47ba-af9b-fb0f2e6d8747",
   "metadata": {},
   "source": [
    "## Create InferenceService \n",
    "Now, with the InferenceService defined, you can now create it by calling the create method of the KServeClient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b954139-3aed-4d42-ae90-470950bac716",
   "metadata": {},
   "outputs": [],
   "source": [
    "KServe = KServeClient()\n",
    "KServe.create(isvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c5b7b-fb26-4991-bea2-3712eec2996e",
   "metadata": {},
   "source": [
    "## Check the InferenceService\n",
    "Run the following command to watch the InferenceService until it is ready (or times out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f03677dd-4713-42dd-b507-866ecf97843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 READY      PREV                      LATEST                    URL                                                              \n",
      "tg-gcn-kserve        Unknown                                                                                                                         \n",
      "tg-gcn-kserve        Unknown                                                                                                                         \n",
      "tg-gcn-kserve        Unknown    0                         100                                                                                        \n",
      "tg-gcn-kserve        Unknown    0                         100                                                                                        \n",
      "tg-gcn-kserve        Unknown    0                         100                                                                                        \n",
      "tg-gcn-kserve        Unknown    0                         100                                                                                        \n",
      "tg-gcn-kserve        Unknown    0                         100                                                                                        \n",
      "tg-gcn-kserve        Unknown    0                         100                                                                                        \n",
      "tg-gcn-kserve        True       0                         100                       http://tg-gcn-kserve.kubeflow-user-example-com.example.com       \n"
     ]
    }
   ],
   "source": [
    "KServe.get(name, namespace=namespace, watch=True, timeout_seconds=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525a2ca-1f85-487a-8621-8f11abaee8e1",
   "metadata": {},
   "source": [
    "## Perform Inference \n",
    "Next, you can try sending an inference request to the deployed model in order to get predictions. This notebook assumes that you running it in your Kubeflow cluster and will use the internal URL of the InferenceService."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7863921-ca24-4920-a510-3190a05cdecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'serving.kserve.io/v1beta1',\n",
       " 'kind': 'InferenceService',\n",
       " 'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'},\n",
       "  'creationTimestamp': '2022-06-09T19:12:38Z',\n",
       "  'finalizers': ['inferenceservice.finalizers'],\n",
       "  'generation': 1,\n",
       "  'managedFields': [{'apiVersion': 'serving.kserve.io/v1beta1',\n",
       "    'fieldsType': 'FieldsV1',\n",
       "    'fieldsV1': {'f:metadata': {'f:annotations': {'.': {},\n",
       "       'f:sidecar.istio.io/inject': {}}},\n",
       "     'f:spec': {'.': {}, 'f:predictor': {'.': {}, 'f:containers': {}}}},\n",
       "    'manager': 'OpenAPI-Generator',\n",
       "    'operation': 'Update',\n",
       "    'time': '2022-06-09T19:12:35Z'},\n",
       "   {'apiVersion': 'serving.kserve.io/v1beta1',\n",
       "    'fieldsType': 'FieldsV1',\n",
       "    'fieldsV1': {'f:metadata': {'f:finalizers': {'.': {},\n",
       "       'v:\"inferenceservice.finalizers\"': {}}},\n",
       "     'f:status': {'.': {},\n",
       "      'f:address': {'.': {}, 'f:url': {}},\n",
       "      'f:components': {'.': {},\n",
       "       'f:predictor': {'.': {},\n",
       "        'f:address': {'.': {}, 'f:url': {}},\n",
       "        'f:latestCreatedRevision': {},\n",
       "        'f:latestReadyRevision': {},\n",
       "        'f:latestRolledoutRevision': {},\n",
       "        'f:traffic': {},\n",
       "        'f:url': {}}},\n",
       "      'f:conditions': {},\n",
       "      'f:url': {}}},\n",
       "    'manager': 'manager',\n",
       "    'operation': 'Update',\n",
       "    'time': '2022-06-09T19:13:00Z'}],\n",
       "  'name': 'tg-gcn-kserve',\n",
       "  'namespace': 'kubeflow-user-example-com',\n",
       "  'resourceVersion': '106995801',\n",
       "  'uid': '88f4e633-aac3-45b3-ad60-0eb46678fb1c'},\n",
       " 'spec': {'predictor': {'containers': [{'image': 'nzarayeneh/kserve-base:latest',\n",
       "     'name': 'kserve-container',\n",
       "     'resources': {'limits': {'cpu': '500m', 'memory': '500Mi'},\n",
       "      'requests': {'cpu': '100m', 'memory': '200Mi'}}}]}},\n",
       " 'status': {'address': {'url': 'http://tg-gcn-kserve.kubeflow-user-example-com.svc.cluster.local/v1/models/tg-gcn-kserve:predict'},\n",
       "  'components': {'predictor': {'address': {'url': 'http://tg-gcn-kserve-predictor-default.kubeflow-user-example-com.svc.cluster.local'},\n",
       "    'latestCreatedRevision': 'tg-gcn-kserve-predictor-default-00001',\n",
       "    'latestReadyRevision': 'tg-gcn-kserve-predictor-default-00001',\n",
       "    'latestRolledoutRevision': 'tg-gcn-kserve-predictor-default-00001',\n",
       "    'traffic': [{'latestRevision': True,\n",
       "      'percent': 100,\n",
       "      'revisionName': 'tg-gcn-kserve-predictor-default-00001'}],\n",
       "    'url': 'http://tg-gcn-kserve-predictor-default.kubeflow-user-example-com.example.com'}},\n",
       "  'conditions': [{'lastTransitionTime': '2022-06-09T19:13:00Z',\n",
       "    'status': 'True',\n",
       "    'type': 'IngressReady'},\n",
       "   {'lastTransitionTime': '2022-06-09T19:13:00Z',\n",
       "    'severity': 'Info',\n",
       "    'status': 'True',\n",
       "    'type': 'PredictorConfigurationReady'},\n",
       "   {'lastTransitionTime': '2022-06-09T19:13:00Z',\n",
       "    'status': 'True',\n",
       "    'type': 'PredictorReady'},\n",
       "   {'lastTransitionTime': '2022-06-09T19:12:59Z',\n",
       "    'severity': 'Info',\n",
       "    'status': 'True',\n",
       "    'type': 'PredictorRouteReady'},\n",
       "   {'lastTransitionTime': '2022-06-09T19:13:00Z',\n",
       "    'status': 'True',\n",
       "    'type': 'Ready'}],\n",
       "  'url': 'http://tg-gcn-kserve.kubeflow-user-example-com.example.com'}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "isvc_resp = KServe.get(name, namespace=namespace)\n",
    "isvc_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49c3ea45-e4c3-428c-962f-da78da5db33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://tg-gcn-kserve.kubeflow-user-example-com.svc.cluster.local/v1/models/tg-gcn-kserve:predict\n",
      "{\"predictions\": [{\"primary_id\": \"7\", \"label\": 3}, {\"primary_id\": \"999\", \"label\": 2}]}\n"
     ]
    }
   ],
   "source": [
    "isvc_url = isvc_resp['status']['address']['url']\n",
    "\n",
    "print(isvc_url)\n",
    "\n",
    "inference_input = {\n",
    "    \"nodes\": [\n",
    "      {\"primary_id\": 7, \"type\": \"Paper\"}, \n",
    "      {\"primary_id\": 999, \"type\": \"Paper\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(isvc_url, json=inference_input)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfce19a-7a17-49b4-b883-ebf5830ebe83",
   "metadata": {},
   "source": [
    "You should see two predictions returned (i.e. `{\"predictions\": [{\"primary_id\": \"7\", \"label\": 3}, {\"primary_id\": \"999\", \"label\": 2}]}`). Two sets of data points sent for inference correspond to the lable `3` and `2`, respectively. In this case, the model predicts that primary_id 7 has label 3, and primary_id 999 has label 2.\n",
    "\n",
    "To learn more about sending inference requests, please check out the [KServe guide](https://kserve.github.io/website/0.7/get_started/first_isvc/#3-determine-the-ingress-ip-and-ports).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3a3d3-d0ce-44ca-9e9e-026b21796c17",
   "metadata": {},
   "source": [
    "## Delete InferenceService\n",
    "When you are done with your InferenceService, you can delete it by running the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7c254-4f3b-4cb3-9b6f-851fb45e7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "KServe.delete(name, namespace=namespace)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
